{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Turnover\n",
    "\n",
    "#### Why Does Turnover Matter?\n",
    "Good analytics practice is to make sure you're focusing on something that matters.  The goal of analytics in any corporate function is to make better decisions, so why do companies and HR departments want to make better decisions when it comes to turnover?  The answer to this likely varies by company, however one common string is that turnover is expensive for companies.  Like many things in HR, measurement isn't always obvious, turnover is no different.  Some parts of turnover can be objectively measured, the cost of the Talent Acquisition function and their time allocation for net new hires compared to backfills.  Other measures are a bit more subjective and rely on research to estimate costs.  An example of this is the productivity lost for a position being open.  Regardless of the measurement, most leaders believe that turnover is expensive to their company and that reducing it will have a positive impact on their bottom line.  \n",
    "\n",
    "While the focus of this book isn't on how to run your People Analytics function, more and more experts and pointing out how critical it is that the analytics HR is producing are directly tied to the overall business objectives.\n",
    "\n",
    "## Two Methodologies for Predicting Turnover\n",
    "\n",
    "Based on my research and experience, there are two primary methodologies for building a predictive model that predicts employee turnover:  *Survival Analysis* and *Turnover Risk in X Time Period*\n",
    "\n",
    "#### Survival Analysis\n",
    "This will not be the methodology for the code in the chapter, however I still want to at least briefly discuss the approach as it is best to understand your options and know *why* this survival analysis methodology may not be the best analytics tool for the turnover prediction business problem.\n",
    "\n",
    "The survival analysis concept is simple.  How long do people stay after they start with our company?  The value of this should be quite apparent.  If you could incorporate a model into your talent acquisition process that could predict how long someone would stay at a company with even moderate accuracy, your model could produce significant value back to your company.  This is one of the greatest benefits to this analysis approach, the interpretation of the results are intuitive and easy to communicate to non-technical audiences.  The results could be communicated as “we expect candidate A to stay for X years and candidate B to stay for Y years”.  This is simple and easy for almost any audience to understand!\n",
    "\n",
    "Unfortunately, there are some significant limitations with survival analysis.  The most significant is data availability.  To properly set up a survival analysis model, you will want to have data for all of your employees for the entirety of their tenure.  For legacy companies that have been around for 50+ years and have long tenured employees, this is likely an unrealistic expectation given the number of HRIS’s and a probability of some longer tenured employees starting when records were mostly paper.  For newer companies started within the last 20 years, you may have the opposite problem, you don’t have enough longer tenured employees to do a survival analysis.  In both cases, even if the necessary data can be utilized, the emergence of data privacy laws like GDPR will only become more restrictive in regards to data retention.  In summary, most companies probably don’t have the necessary data to utilize survival analysis for predicting turnover and those that do may be required to anonymize or delete the data necessary for survival analysis. \n",
    "\n",
    "#### Turnover Risk in X Time Period\n",
    "The code in this chapter uses this methodology.  In general, this approach is more flexible to various company’s needs and is more conductive for informing interventions to reduce turnover risk.\n",
    "\n",
    "This methodology requires some what of a mindset shift than is typically leveraged by humans.  Humans are more comfortable in speaking in absolutes.  When it comes to predictive modeling (and specifically this approach to predicting turnover risk), this can be a great cause of frustration between the analytics team and the business user trying to interpret the results.   The output from this approach is a probability of turnover in the time period you have set in the model.  No matter how cool your model is, you will rarely be able to (or want to) speak in absolutes.  For help with not speaking/thinking in absolutes, [*Thinking in Bets*]( https://www.amazon.com/Thinking-Bets-Making-Smarter-Decisions/dp/0735216355) by Annie Duke is a book I would recommend!\n",
    "\n",
    "As stated above, the flexibility of this approach is probably its biggest benefit.  Once you have defined what 1 row equals, you can continue to add additional features (the data science community can’t agree on anything, so feature, column, and attribute all mean the same thing) into the model that you believe will add prediction power and the model will scale.  The model is smart enough to only take what is going to provide predictive power, so you can add the shoe color of all your employees into your model if you want.  If there isn’t any predictive power in employee shoe color, it simply won’t be used in the model.  \n",
    "\n",
    "At this point, anyone with an I/O Psych background is probably cringing and yelling something along the lines of *“you’re going to start finding correlations that don’t matter, are by chance, or are confounds”*.  This is where model development gets a bit more “squishy” and subjective.  The model we’re using (GBM) will take care of the confounds, which is a handy benefit to a GBM because it is doing feature selection for you as well as removing the potential for human error in feature selection.  However, we still want to be mindful of what features we are putting into the model and how it relates to our use case.\n",
    "\n",
    "If your use case is related back to an intervention we want to test on our workforce, what would happen if employee shoe color came back as our most important variable?  Would you really try an experiment that changes the shoe color of some of your employees and check the change in turnover?  Good luck getting your leaders to approve that!\n",
    "\n",
    "A good rule of thumb to follow is a yes to the following questions:\n",
    "1. *Is there is already research done on your feature in question?* There are a lot of really smart people who have already done a ton of research on turnover.  If they have already found a relationship between your feature and turnover, you should feel comfortable adding the feature into your model.\n",
    "2. *If this variable returned as one of the most predictive, would you be able to provide a potential reason as to why?* Using the shoe color example again, I’d have a hard time finding an explanation where employee shoe color actually influences shoe color.  Maybe it is a confound for age? (insert joke about dads wearing white Nike shoes)\n",
    "\n",
    "#### Chapter 3 Overview\n",
    "This chapter is broken into the following sections\n",
    "1. Set up your data\n",
    "2. Pre-Processing before modeling\n",
    "3. Grid Search and the model\n",
    "4. Understanding your results\n",
    "5. Using your model to predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your data\n",
    "Garbage in, garbage out is a common phrase with data and predicting turnover risk is no exception.  However, there even worse consequences with not setting up your data when building a predictive model, this is called *model leakage*.  This is when you’re telling the model the whole or part of the answer with your inputs to the model.  An easy example is including termination date as a feature in your model, you’d be telling the model the answer!\n",
    "\n",
    "In this section we will be going over the steps to setting up your data in a way that will allow it.  We will be using a generated dataset.  How this dataset was created is outlined in the previous chapter.\n",
    "1. We will discuss the importance of defining what 1 row in your dataset means\n",
    "2. Selecting and defining your target variable \n",
    "3. Adjust our dataset based on how we define our target variable\n",
    "4. How to lag our target variable (**very important**)\n",
    "5. Selecting the columns we want to include in our model\n",
    "6. How to dummy code non-numeric variables \n",
    "7. Discuss feature engineering\n",
    "\n",
    "You'll likely observe the setting up your data section has the most code associated with it.  This is quite typical as the majority of the work when building a model will come from setting up your data rather than actually building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining what one row means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import the necessary packages.  In this instance, we only need Pandas.  If you're an R user, Pandas is similar to dplyr.  If you haven't used R or Python before, Pandas is a manipulation/reshaping library.  We rename Pandas as \"pd\".  This is because each time we want to reference a function within Pandas we only have to write \"pd\" instead of \"pandas\".  Naming Pandas \"pd\" is standard across the Python community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that Pandas is imported, we can use it's function that imports .CSV files.  If you haven't needed to understand the difference between an Excel and CSV file yet, you will now!  Pandas has seperate import functions for a CSV vs. Excel file.  When passing the path of the file, include the entire file path to ensure it knows where to look.\n",
    "\n",
    "When naming your objects or variables in Python, find the balance between length and descriptiveness.  If you're using extremely long names, it will make your code harder to read and take you longer to write it.  If your names aren't descriptive enough, you or anyone else trying to read your code will have a difficult time understanding what is going where and why.  It is a difficult balance to find, but it becomes easier with time!  When importing a new dataset, I usually call it \"df_raw\".  Df stands for dataframe and raw indicates it hasn't been manipulated at all.  By doing this, I can redo any manipulations to my dataset without having to reimport the raw data.\n",
    "\n",
    "If you get an error right away, the first thing to check is if your file is still open.  Depending on where your file is saved, it may need to be closed for it to be loaded via Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>gender</th>\n",
       "      <th>job_level</th>\n",
       "      <th>performance_rating</th>\n",
       "      <th>engagement</th>\n",
       "      <th>salary_thousands</th>\n",
       "      <th>tenure_years</th>\n",
       "      <th>age_years</th>\n",
       "      <th>promotion_indicator</th>\n",
       "      <th>record_start_date</th>\n",
       "      <th>record_end_date</th>\n",
       "      <th>termination_indicator</th>\n",
       "      <th>termination_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>109</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>143</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id                 department gender               job_level  \\\n",
       "0            0  Account/Client Management   Male  Individual Contributor   \n",
       "1            1                 Technology   Male  Individual Contributor   \n",
       "2            2  Account/Client Management   Male  Individual Contributor   \n",
       "3            3  Account/Client Management   Male  Individual Contributor   \n",
       "4            4  Account/Client Management   Male  Individual Contributor   \n",
       "\n",
       "   performance_rating  engagement  salary_thousands  tenure_years  age_years  \\\n",
       "0                 2.0         3.0               165            49         36   \n",
       "1                 4.0         5.0                68            23         25   \n",
       "2                 4.0         5.0               109            11         33   \n",
       "3                 4.0         3.0               143            27         52   \n",
       "4                 3.0         5.0                83             8         34   \n",
       "\n",
       "   promotion_indicator record_start_date record_end_date  \\\n",
       "0                    0          1/1/2018      12/31/2018   \n",
       "1                    1          1/1/2018      12/31/2018   \n",
       "2                    0          1/1/2018      12/31/2018   \n",
       "3                    0          1/1/2018      12/31/2018   \n",
       "4                    0          1/1/2018      12/31/2018   \n",
       "\n",
       "   termination_indicator termination_date  \n",
       "0                      0              NaN  \n",
       "1                      0              NaN  \n",
       "2                      0              NaN  \n",
       "3                      0              NaN  \n",
       "4                      0              NaN  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"employee_data_turnover_model.csv\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset is loaded from the .CSV file, 1 row equates to a period of time.  The period of time is defined by the columns \"record_start_date\" and \"record_end_date\".  This means an employee could have multiple records in our dataset.  While this often complicates our ability to do reporting or basic descriptive statistics on our data, this means more data for our model which is almost always a good thing!  A model that predicts employee turnover can leverage multiple data formats and this framework can be adjusted to account for them.  In this example, we will be taking an approach to further increase the size of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting and Defining Target Variable\n",
    "\n",
    "If you're not familiar with the terminology, a target variable is what we're trying to predict.  The approach we are taking has been defined as \"Turnover in X period of time\".  This is where we will define what X is equal to.\n",
    "\n",
    "When defining X, you need to understand the usage of the model results to your company.  If you're using it to test an intervention on the high risk employees to determine if the termination rate for the treatment group can be reduced, what time period is actionable?  As a general rule, if your company is experiencing high turnover, default to a lower time period like 3 months.  This can then be paired with a treatment that accounts for this shorter term view.  If your company is using this model to simply understand the risk of turnover, it may make sense to define multiple values for X and run a model for each value of X.  For example, running a model for 3, 6, 12, and 18 months will provide a more complete view than defining a single value of X.\n",
    "\n",
    "Because my head isn't in the sand, I also need to acknowledge the data limitations on how you define X as well.  Like in our example, if you only have 1 year of data, you literally can't define X as 18 months.  You won't get great results if you define X as 12 months because you're opening yourself up to yearly seasonality for future years.\n",
    "\n",
    "For this model, we will define our target variable as turnover in the next 2 months.  When we lag our data you'll see why having only 1 month isn't ideal from an example standpoint.  You'll also see why having 3 months would eliminate 25% of our data vs. the 17% data beginning eliminated with a 2 month target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust Dataset Based on Target Variable Definition\n",
    "Now that we have defined our target variable as 2 months, we will want to do a *Cartesian Join* to adjust our definition of a row to one row per employee per month.  This means for each month an employee is active they will have a record.  An employee who is active for the entire year ends up with 12 rows.  An employee who terminates in June ends up with 6 rows.\n",
    "\n",
    "To do this, we will reference a file that has the last date of each month in 2018.  If you're doing this across multiple years, there are some existing lists available online.  You can also create your own list in Python.  The \"calendar\" library has the tools necessary to generate this programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sop_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11/1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12/1/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sop_month\n",
       "0    1/1/2018\n",
       "1    2/1/2018\n",
       "2    3/1/2018\n",
       "3    4/1/2018\n",
       "4    5/1/2018\n",
       "5    6/1/2018\n",
       "6    7/1/2018\n",
       "7    8/1/2018\n",
       "8    9/1/2018\n",
       "9   10/1/2018\n",
       "10  11/1/2018\n",
       "11  12/1/2018"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sop_month = pd.read_csv(\"start_of_month.csv\")\n",
    "sop_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually execute this join is annoyingly difficult with just Pandas.  The number of jokes playing on the SQL vs. sequel is amazing.  My favorite is \"(sometimes) a SQL is better than the original\".  The approach we will use here is quite inefficient but we can get away with because our dataset is relatively small.  We will be joining each date onto every record, blowing up our dataset to 12x it currently is.  Then we'll filter using some conditional logic on the dates.  To simplify this, we will create a dummy column on both datasets to join on.  The type of join we do in this instance won't matter because everything will match to everything.\n",
    "\n",
    "If your dataset is larger, I'd suggest spinning up a SQL lite database (import sqlite3).  This will enable you do utilize SQL to execute your join with the conditional logic, rather than joining everything and then filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['for_join'] = 0\n",
    "sop_month['for_join'] = 0\n",
    "\n",
    "df_long = pd.merge(df_raw, sop_month, how = 'inner', on='for_join')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you some perspective on how much larger our dataset is, see the below.  As I had said above, it is now 12 times larger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Employee Data:  15222\n",
      "New Employee Data:  182664\n",
      "Number of times larger:  12.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Employee Data: \", df_raw.shape[0])\n",
    "print(\"New Employee Data: \", df_long.shape[0])\n",
    "print(\"Number of times larger: \", df_long.shape[0] / df_raw.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to filter down our dataset to only the records we want to keep based on the dates being between the appropriate values.  Through my learning of R and Python, dates have always been a point of frustration for myself.  There are a ton of different date types and not all are work together.  In this instance we want to make sure our data types are the same for the dates we will filter on.  They are not, so we will also make the adjustment to our date fields using the Pandas to_datetime() function.\n",
    "\n",
    "Sometimes the issue with your column not actually being a date is simply annoying, as you'll get an error message that you can use to debug.  However, in other instances if your date has a data type of an object or string, it will run successfully but give you a result you weren't expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long['sop_month'] = pd.to_datetime(df_shorter['sop_month'])\n",
    "df_long['record_start_date'] = pd.to_datetime(df_shorter['record_start_date'])\n",
    "df_long['record_end_date'] = pd.to_datetime(df_shorter['record_end_date'])\n",
    "\n",
    "df_shorter = df_long[(df_long['sop_month'] >= df_long['record_start_date']) & (df_long['sop_month'] <= df_long['record_end_date'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking another look at how much the data reduces and what the new size is compared to the original dataset we imported from CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Data After Join:  182664\n",
      "Employee Data After Filtering:  53091\n",
      "Number of times smaller:  3.4405831496863875\n",
      "New dataset compared to the original:  3.4877808435159636\n"
     ]
    }
   ],
   "source": [
    "print(\"Employee Data After Join: \", df_long.shape[0])\n",
    "print(\"Employee Data After Filtering: \", df_shorter.shape[0])\n",
    "print(\"Number of times smaller: \", df_long.shape[0] / df_shorter.shape[0])\n",
    "print(\"New dataset compared to the original: \", df_shorter.shape[0] / df_raw.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lagging the Target Variable\n",
    "**This is really important!!!**\n",
    "\n",
    "We're trying to predict the probability of an employee terminating in the next 2 months.  Based on that, we need to have our target variable show in the two months prior to the actual termination record, not the actual row in which the termination occurred.  As I mentioned above about the data loss from extending our time frame for our target variable, each additional month we select, is another month we cannot include in our final dataset because the lagged data doesn't have anywhere to go.  For example, January 2018 is the earliest our dataset goes, so it cannot be lagged anywhere effectively removing it our dataset.  Since we only selected 2 months, we only lose January and February.\n",
    "\n",
    "We do need to do some prep work for our termination date field.  I'll use employee 31 to demonstrate why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>gender</th>\n",
       "      <th>job_level</th>\n",
       "      <th>performance_rating</th>\n",
       "      <th>engagement</th>\n",
       "      <th>salary_thousands</th>\n",
       "      <th>tenure_years</th>\n",
       "      <th>age_years</th>\n",
       "      <th>promotion_indicator</th>\n",
       "      <th>record_start_date</th>\n",
       "      <th>record_end_date</th>\n",
       "      <th>termination_indicator</th>\n",
       "      <th>termination_date</th>\n",
       "      <th>for_join</th>\n",
       "      <th>sop_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>7/31/2018 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>7/31/2018 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>7/31/2018 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>7/31/2018 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>7/31/2018 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>7/31/2018 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>7/31/2018 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     employee_id                 department  gender               job_level  \\\n",
       "372           31  Account/Client Management  Female  Individual Contributor   \n",
       "373           31  Account/Client Management  Female  Individual Contributor   \n",
       "374           31  Account/Client Management  Female  Individual Contributor   \n",
       "375           31  Account/Client Management  Female  Individual Contributor   \n",
       "376           31  Account/Client Management  Female  Individual Contributor   \n",
       "377           31  Account/Client Management  Female  Individual Contributor   \n",
       "378           31  Account/Client Management  Female  Individual Contributor   \n",
       "\n",
       "     performance_rating  engagement  salary_thousands  tenure_years  \\\n",
       "372                 3.0         1.0               119             6   \n",
       "373                 3.0         1.0               119             6   \n",
       "374                 3.0         1.0               119             6   \n",
       "375                 3.0         1.0               119             6   \n",
       "376                 3.0         1.0               119             6   \n",
       "377                 3.0         1.0               119             6   \n",
       "378                 3.0         1.0               119             6   \n",
       "\n",
       "     age_years  promotion_indicator record_start_date record_end_date  \\\n",
       "372         31                    0        2018-01-01      2018-07-31   \n",
       "373         31                    0        2018-01-01      2018-07-31   \n",
       "374         31                    0        2018-01-01      2018-07-31   \n",
       "375         31                    0        2018-01-01      2018-07-31   \n",
       "376         31                    0        2018-01-01      2018-07-31   \n",
       "377         31                    0        2018-01-01      2018-07-31   \n",
       "378         31                    0        2018-01-01      2018-07-31   \n",
       "\n",
       "     termination_indicator termination_date  for_join  sop_month  \n",
       "372                      1   7/31/2018 0:00         0 2018-01-01  \n",
       "373                      1   7/31/2018 0:00         0 2018-02-01  \n",
       "374                      1   7/31/2018 0:00         0 2018-03-01  \n",
       "375                      1   7/31/2018 0:00         0 2018-04-01  \n",
       "376                      1   7/31/2018 0:00         0 2018-05-01  \n",
       "377                      1   7/31/2018 0:00         0 2018-06-01  \n",
       "378                      1   7/31/2018 0:00         0 2018-07-01  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shorter[(df_shorter['employee_id'] == 31)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above, this individual's termination date is shown on every record.  What we want to do is adjust this to only put it in the month in which the individual terminated.  We will do this by extracting the month of the date using Pandas DatetimeIndex() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\jason\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>gender</th>\n",
       "      <th>job_level</th>\n",
       "      <th>performance_rating</th>\n",
       "      <th>engagement</th>\n",
       "      <th>salary_thousands</th>\n",
       "      <th>tenure_years</th>\n",
       "      <th>age_years</th>\n",
       "      <th>promotion_indicator</th>\n",
       "      <th>record_start_date</th>\n",
       "      <th>record_end_date</th>\n",
       "      <th>termination_indicator</th>\n",
       "      <th>termination_date</th>\n",
       "      <th>for_join</th>\n",
       "      <th>sop_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>31</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Female</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     employee_id                 department  gender               job_level  \\\n",
       "372           31  Account/Client Management  Female  Individual Contributor   \n",
       "373           31  Account/Client Management  Female  Individual Contributor   \n",
       "374           31  Account/Client Management  Female  Individual Contributor   \n",
       "375           31  Account/Client Management  Female  Individual Contributor   \n",
       "376           31  Account/Client Management  Female  Individual Contributor   \n",
       "377           31  Account/Client Management  Female  Individual Contributor   \n",
       "378           31  Account/Client Management  Female  Individual Contributor   \n",
       "\n",
       "     performance_rating  engagement  salary_thousands  tenure_years  \\\n",
       "372                 3.0         1.0               119             6   \n",
       "373                 3.0         1.0               119             6   \n",
       "374                 3.0         1.0               119             6   \n",
       "375                 3.0         1.0               119             6   \n",
       "376                 3.0         1.0               119             6   \n",
       "377                 3.0         1.0               119             6   \n",
       "378                 3.0         1.0               119             6   \n",
       "\n",
       "     age_years  promotion_indicator record_start_date record_end_date  \\\n",
       "372         31                    0        2018-01-01      2018-07-31   \n",
       "373         31                    0        2018-01-01      2018-07-31   \n",
       "374         31                    0        2018-01-01      2018-07-31   \n",
       "375         31                    0        2018-01-01      2018-07-31   \n",
       "376         31                    0        2018-01-01      2018-07-31   \n",
       "377         31                    0        2018-01-01      2018-07-31   \n",
       "378         31                    0        2018-01-01      2018-07-31   \n",
       "\n",
       "     termination_indicator termination_date  for_join  sop_month  \n",
       "372                  False       2018-07-31         0 2018-01-01  \n",
       "373                  False       2018-07-31         0 2018-02-01  \n",
       "374                  False       2018-07-31         0 2018-03-01  \n",
       "375                  False       2018-07-31         0 2018-04-01  \n",
       "376                  False       2018-07-31         0 2018-05-01  \n",
       "377                  False       2018-07-31         0 2018-06-01  \n",
       "378                   True       2018-07-31         0 2018-07-01  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shorter['termination_date'] = pd.to_datetime(df_shorter['termination_date'])\n",
    "\n",
    "df_shorter['termination_indicator'] = pd.DatetimeIndex(df_shorter['termination_date']).month == pd.DatetimeIndex(df_shorter['sop_month']).month\n",
    "\n",
    "df_shorter[(df_shorter['employee_id'] == 31)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the termination_indicator column has been updated to only include the termination in the row that represents the time period in which it occured.\n",
    "\n",
    "Now we will finally get to the point of this section, actually lagging our target variable!  Since we are only lagging by 2 periods, we will take the manual approach and create 2 series.  Each will have the length of our original dataset, so it can be put right back into our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged_1 = df_shorter['termination_indicator'].shift(periods = -1) \n",
    "df_lagged_2 = df_shorter['termination_indicator'].shift(periods = -2) \n",
    "\n",
    "combined_lists = zip(df_lagged_1, df_lagged_2)\n",
    "\n",
    "lagged_data = pd.DataFrame(combined_lists, columns = ['lag_1', 'lag_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When possible, it is usually preferred to use math functions as it is usually provides you more flexibility/options.  In the spirit of this, we will replace our True values to 1's and our False values to 0's.  Once we do that, we'll create a new column that is the max value of either of those 2 columns.  This allows us combine the 2 columns into a single value that can be added back onto our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_data = lagged_data.replace(to_replace = True, value = 1)\n",
    "lagged_data = lagged_data.replace(to_replace = False, value = 0)\n",
    "\n",
    "lagged_data['2_month_term'] = lagged_data.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to add the column back onto the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>gender</th>\n",
       "      <th>job_level</th>\n",
       "      <th>performance_rating</th>\n",
       "      <th>engagement</th>\n",
       "      <th>salary_thousands</th>\n",
       "      <th>tenure_years</th>\n",
       "      <th>age_years</th>\n",
       "      <th>promotion_indicator</th>\n",
       "      <th>record_start_date</th>\n",
       "      <th>record_end_date</th>\n",
       "      <th>termination_indicator</th>\n",
       "      <th>termination_date</th>\n",
       "      <th>for_join</th>\n",
       "      <th>sop_month</th>\n",
       "      <th>2_month_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employee_id                 department gender               job_level  \\\n",
       "0             0  Account/Client Management   Male  Individual Contributor   \n",
       "9             0  Account/Client Management   Male  Individual Contributor   \n",
       "10            0  Account/Client Management   Male  Individual Contributor   \n",
       "11            0  Account/Client Management   Male  Individual Contributor   \n",
       "12            1                 Technology   Male  Individual Contributor   \n",
       "\n",
       "    performance_rating  engagement  salary_thousands  tenure_years  age_years  \\\n",
       "0                  2.0         3.0               165            49         36   \n",
       "9                  2.0         3.0               165            49         36   \n",
       "10                 2.0         3.0               165            49         36   \n",
       "11                 2.0         3.0               165            49         36   \n",
       "12                 4.0         5.0                68            23         25   \n",
       "\n",
       "    promotion_indicator record_start_date record_end_date  \\\n",
       "0                     0        2018-01-01      2018-12-31   \n",
       "9                     0        2018-01-01      2018-12-31   \n",
       "10                    0        2018-01-01      2018-12-31   \n",
       "11                    0        2018-01-01      2018-12-31   \n",
       "12                    1        2018-01-01      2018-12-31   \n",
       "\n",
       "    termination_indicator termination_date  for_join  sop_month  2_month_term  \n",
       "0                   False              NaT         0 2018-01-01           0.0  \n",
       "9                   False              NaT         0 2018-10-01           0.0  \n",
       "10                  False              NaT         0 2018-11-01           0.0  \n",
       "11                  False              NaT         0 2018-12-01           0.0  \n",
       "12                  False              NaT         0 2018-01-01           0.0  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged = df_shorter\n",
    "df_lagged['2_month_term'] = lagged_data['2_month_term']\n",
    "df_lagged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you'll see the newly created column on the back of the dataset.  \n",
    "\n",
    "As a summary of this section.  When generating predictions that has a time period associated with the prediction, we need to ensure the \"right answer\" isn't in the field in which it exists, it needs to be moved to the X number of time periods prior.  What we define our time period as will depend on our business case as well as our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Columns\n",
    "\n",
    "Since we've done quite a bit of actions to our data, we want to select only the columns we know we want to include in our model.  Below is a list of the columnns in our dataset.  Before reading on, which columns do you think should be removed and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee_id\n",
      "department\n",
      "gender\n",
      "job_level\n",
      "performance_rating\n",
      "engagement\n",
      "salary_thousands\n",
      "tenure_years\n",
      "age_years\n",
      "promotion_indicator\n",
      "record_start_date\n",
      "record_end_date\n",
      "termination_indicator\n",
      "termination_date\n",
      "for_join\n",
      "sop_month\n",
      "2_month_term\n"
     ]
    }
   ],
   "source": [
    "for col in df_lagged.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start with what not to keep.\n",
    "\n",
    "*employee_id*: If we included this, our model would be able to pick up quite quickly on who is who and associate that with other records.  We want each observation to be unique, so removing the employee number is critical.\n",
    "\n",
    "*record_start_date* and *record_end_date*: These don't represent anything of meaning in our dataset anymore now that we have sop_month, so they can be removed.\n",
    "\n",
    "*termination_indicator*: Since we have lagged our termination data and put it into 2_month_term, this column represents terminations in a way that we don't want so it should be removed.\n",
    "\n",
    "*termination_date*: Similar to termination_indicator, we had to manipulate this field to make it into something else we need.\n",
    "\n",
    "*for_join*: This columns purpose was to join our data with the sop_month dates.  Since this has been done, we can now remove it.\n",
    "\n",
    "Now that we know which columns we don't want, let's select the ones we do want.  Something of note, it is best practice to put your target variable at the end of your dataset.  This allows you to use positional arguements when selecting your inputs vs. your target variable in your model: \"Select the last column vs. select the column of this name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>gender</th>\n",
       "      <th>job_level</th>\n",
       "      <th>performance_rating</th>\n",
       "      <th>engagement</th>\n",
       "      <th>salary_thousands</th>\n",
       "      <th>tenure_years</th>\n",
       "      <th>age_years</th>\n",
       "      <th>promotion_indicator</th>\n",
       "      <th>sop_month</th>\n",
       "      <th>2_month_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Account/Client Management</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Technology</td>\n",
       "      <td>Male</td>\n",
       "      <td>Individual Contributor</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   department gender               job_level  \\\n",
       "0   Account/Client Management   Male  Individual Contributor   \n",
       "9   Account/Client Management   Male  Individual Contributor   \n",
       "10  Account/Client Management   Male  Individual Contributor   \n",
       "11  Account/Client Management   Male  Individual Contributor   \n",
       "12                 Technology   Male  Individual Contributor   \n",
       "\n",
       "    performance_rating  engagement  salary_thousands  tenure_years  age_years  \\\n",
       "0                  2.0         3.0               165            49         36   \n",
       "9                  2.0         3.0               165            49         36   \n",
       "10                 2.0         3.0               165            49         36   \n",
       "11                 2.0         3.0               165            49         36   \n",
       "12                 4.0         5.0                68            23         25   \n",
       "\n",
       "    promotion_indicator  sop_month  2_month_term  \n",
       "0                     0 2018-01-01           0.0  \n",
       "9                     0 2018-10-01           0.0  \n",
       "10                    0 2018-11-01           0.0  \n",
       "11                    0 2018-12-01           0.0  \n",
       "12                    1 2018-01-01           0.0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_needed_cols = df_lagged[['department', \n",
    "                   'gender', \n",
    "                   'job_level', \n",
    "                   'performance_rating', \n",
    "                   'engagement', \n",
    "                   'salary_thousands', \n",
    "                   'tenure_years', \n",
    "                   'age_years', \n",
    "                   'promotion_indicator', \n",
    "                   'sop_month', \n",
    "                   '2_month_term']]\n",
    "\n",
    "df_needed_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Coding\n",
    "As smart as models can be, they require numeric information.  Our way to include non-numeric data into a model is to leverage dummy coding.  This is where we take each value from our categorical column and create it as a new column.  If the row has that value it is assigned a 1, if it doesn't, it is assigned a 0.  Something to consider is the cardinality, or how many values are in your categorical column.  For a column like gender, you may only have a few values.  For a column like job title, you may have hundreds or thousands of values making job title difficult to use in the model.  \n",
    "\n",
    "Thankfully, Pandas has a really easy function that does all the heavy lifting on this for us!  Another concept to understand with dummy coding is dropping one of your values.  For example, with job_level, we have Individual Contributor, Manager, Senior Leader, and Executive.  We don't need all 4 values, only 3 as a row with 0's for all of these columns can be assumed to be the missing value.  As humans this isn't intuitive and we feel like we're losing information because if Executive is drop, we know additional context about an Executive role that doesn't exist in our data.  Since our model doesn't know that context unless we provide it, we don't need to keep all values in after dummy coding.\n",
    "\n",
    "When the new dummy coded columns are created, they're automatically added to the end.  The account for this, I'll remove the target variable and put it back after the dummy coding has been executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>performance_rating</th>\n",
       "      <th>engagement</th>\n",
       "      <th>salary_thousands</th>\n",
       "      <th>tenure_years</th>\n",
       "      <th>age_years</th>\n",
       "      <th>promotion_indicator</th>\n",
       "      <th>sop_month</th>\n",
       "      <th>department_Corporate Admin (HR, Finance, etc)</th>\n",
       "      <th>department_Technology</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>job_level_Individual Contributor</th>\n",
       "      <th>job_level_Manager</th>\n",
       "      <th>job_level_Senior Leader</th>\n",
       "      <th>2_month_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    performance_rating  engagement  salary_thousands  tenure_years  age_years  \\\n",
       "0                  2.0         3.0               165            49         36   \n",
       "9                  2.0         3.0               165            49         36   \n",
       "10                 2.0         3.0               165            49         36   \n",
       "11                 2.0         3.0               165            49         36   \n",
       "12                 4.0         5.0                68            23         25   \n",
       "\n",
       "    promotion_indicator  sop_month  \\\n",
       "0                     0 2018-01-01   \n",
       "9                     0 2018-10-01   \n",
       "10                    0 2018-11-01   \n",
       "11                    0 2018-12-01   \n",
       "12                    1 2018-01-01   \n",
       "\n",
       "    department_Corporate Admin (HR, Finance, etc)  department_Technology  \\\n",
       "0                                               0                      0   \n",
       "9                                               0                      0   \n",
       "10                                              0                      0   \n",
       "11                                              0                      0   \n",
       "12                                              0                      1   \n",
       "\n",
       "    gender_Male  job_level_Individual Contributor  job_level_Manager  \\\n",
       "0             1                                 1                  0   \n",
       "9             1                                 1                  0   \n",
       "10            1                                 1                  0   \n",
       "11            1                                 1                  0   \n",
       "12            1                                 1                  0   \n",
       "\n",
       "    job_level_Senior Leader  2_month_term  \n",
       "0                         0           0.0  \n",
       "9                         0           0.0  \n",
       "10                        0           0.0  \n",
       "11                        0           0.0  \n",
       "12                        0           0.0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_var = df_needed_cols['2_month_term']\n",
    "df_needed_cols = df_needed_cols.drop('2_month_term', axis = 1)\n",
    "df_dummied = pd.get_dummies(data = df_needed_cols, columns = ['department', 'gender', 'job_level'], drop_first = True)\n",
    "df_dummied['2_month_term'] = target_var\n",
    "df_dummied.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "While we won't do any feature engineering explicitly here, I did want to at least mention it and discuss its value.\n",
    "\n",
    "Feature engineering is a fancy word for making new columns from other information the model doesn't already have available.  Feature engineering is not making a composite field for tenure and age, tree based models can already do that.  Feature engineering is created a calculated field for how many months since an employees last promotion was.  Again, we're providing the model with brand new information that it may be able to find deep and complex patterns in.\n",
    "\n",
    "This highlights a benefit to tree based approaches (often called \"black box\" models) compared to regression based approaches.  My statement above about a composite field for tenure and age is not accurate if you were using a regression based approach.  When using regression based models, you have to do quite a bit more feature engineering where as with a tree based model you get a lot of that built in already with the model.  This can often result in faster model development times because you need less feature engineering on the front end for the first iteration of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing before modeling\n",
    "This is a baby section compared to setting up your data.  I debated on whether this should be its own section or not and decided to split it out for the sake of breaking up the process into the distinct steps in the process that I leverage.  This step can include normalizing your data if required, however in this example we will only be leveraging the test-train split.  Up to this point, a portion of the code being written is specific to this example dataset's needs for cleaning/prepping.  Starting in this section you should see a bit more standardization of how this specific example code is written and how you would need to write your code.\n",
    "\n",
    "First, we start by doing our first import from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before splitting our data, we want to do a quick check of our data to ensure it will be acceptable for the model.  With this example, we need to replace the blank values for performance and engagement of our new employees with 0's.  In some cases this isn't always possible, so you need to leverage your understanding of your data to know if this is an acceptable replacement or not.  In some cases, you may need to remove these records.\n",
    "\n",
    "When creating our target variable, blanks are introduced, so we will need to replace those with 0's as well.\n",
    "\n",
    "Lastly, our model won't like getting a timestamp, so we will convert that timestamp into the month number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummied['performance_rating'] = df_dummied['performance_rating'].replace(np.nan, 0)\n",
    "df_dummied['engagement'] = df_dummied['engagement'].replace(np.nan, 0)\n",
    "df_dummied['2_month_term'] = df_dummied['2_month_term'].replace(np.nan, 0)\n",
    "\n",
    "df_dummied['sop_month'] = pd.DatetimeIndex(df_dummied['sop_month']).month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned in the previous section, having our target variable as the last column helps us streamline and standardize our code in a way that allows us to copy and paste code and reduce the potential for errors.\n",
    "\n",
    "Below we are creating X, or our inputs into the model.  We then create y, which is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummied.iloc[:,:-1].values\n",
    "y = df_dummied.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to leverage the train_test_split() function from sklearn to split our data into our training and test sets.  With this we need to define the size of our test set.\n",
    "\n",
    "As a general rule, the larger you can make your test set, the better.  The likelihood of getting an unrealistically good result on a test set of 10% vs. a test set of 30% is much higher.  The trade off with this is the size of your data.  If you only have a few hundred employees, you may want to decrease the size of your test set a bit to allow for more data for your model to be trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our inputs and target variable split up into the training and test sets.  A final step that isn't always required, but will never hurt is to standardize the scales of your variables.  This is most important when you have a large difference in the range between your variables.  In this use case, salary has a significantly larger range than any of our other variables.  While this may not impact the model as much, you'll see the impact to our understanding of what variables are important to the model.\n",
    "\n",
    "You'll note we do a fit transform function on the training set, but only a transform on our test set.  This is because our test set needs to be unseen, so we don't want to fit, or adjust how we standardize our data, based on our test data, only our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search and the model\n",
    "\n",
    "Now that we've done all the hard work to get our data into a place that the model can accept it, we can finally start putting together our model!  As common an extremely helpful concept that I want to introduce here is *grid search*.  With grid search, we are providing a range of hyperparameter values for our model to try.  The model then tries all of those combinations (or a random subset of them if we prefer) and tells us which model provides the best results.  With grid search, we are testing *hyperparameters*, or the inputs the model needs to be told by a human.\n",
    "\n",
    "When learning about this concept, I often questioned the need for hyperparameters.  Wondering why we couldn't simply look over every possible value and find the truly optimal solution.  Well, in theory you could, however to do this would require a significant amount of computer power.  Imagine if you worked for Amazon trying to build an employee attrition model.  They have hundreds of thousands of employees, and running a single iteration of that model may take an hour to run.  Now what happens if you try 50 different combinations of hyperparameters?  You're up to over 2 days of processing time, often an unrealistic time frame to try and test and learn.  As you build more models, you'll begin to get a better feel for what hyperparameters make sense on what type of data without needing to exhaust every possible option in the process!\n",
    "\n",
    "#### Intro to GBM's\n",
    "GBM's or Gridient Boosting Machines are one of the most common models used in the data science space today.  Their ability to produce accurate predictions is incredible.  However, this comes at the expense of interpretability and is why this type of model gets labeled a black box model.  Think about the GBM as a witch mixing a bunch of different ingredients (model inputs) into her cauldron (GBM).  She starts mixing everything up and it creates a potion (predictions), but breaking apart that potion to understand how it became the potion is extremely difficult.  Depending on how the potion will be used will likely determine if you want to use the potion or not (based on your business case, do you want to use those predictions).  Okay, I'm done with the analogy now.  All this being said, GBM's are very powerful models, but also should not be blindly used and put out into your company without deliberate thought as to how the results will be utilized.\n",
    "\n",
    "To provide some more detail on why GBM's are so good at predicting, we will need to hit on the concept of ensembling.  The most basic definition is a bunch of weaker (not all the rows or columns) models being brought together will create a better prediction than 1 strong model.  That is what a GBM does, it creates a bunch of weak decision trees that build off of each other.  If you're familiar with a random forest algorithm, the primary difference is in a random forest the decision trees are independently created from each other.  With a GBM, the decision trees build upon one another.\n",
    "\n",
    "#### Code to generate model\n",
    "We will start by importing the various packages we will need to build and test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create the grid our model will utilize the test the various hyperparameters.  I'll provide some brief explanation of the hyperparameters we're using here, but sklearn has incredible documentation that you can leverage if you want to learn more.\n",
    "\n",
    "*n_estimators*: How many decision trees will be created.\n",
    "\n",
    "*min_samples_split*: How many rows must be present for another split in a decision tree to occur.  If you let this be one, you would risk overfitting on your training set.\n",
    "\n",
    "*max_depth*: How many splits each decision tree can make.  If you let the tree get too deep, you risk overfitting on your training set.\n",
    "\n",
    "When setting your grid search, default to starting small and iterating.  If you start with a ton of options, it will take awhile for your code to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_inputs = {'n_estimators': [150,200], \n",
    "             'min_samples_split': [25, 50], \n",
    "             'max_depth': [4, 5, 6]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Fold Validations\n",
    "Cross validations fit into the category of very easy to implement, but a bit more difficult to understand what is happening on the backend of the function.  The purpose of doing a cross validation is to help prevent overfitting in your model.  It does this by breaking up your training data into the number of parts you specify with the “cv” parameter in the GridSearchCV function.  In this case, it will split my training set further.  This effectively creates additional models by the multiple of how many cross folds you specify.  Pairing this will your grid search parameters, they have a multiplicative relationship, meaning for each cross fold you have, you have to multiple the number of models you would already be testing by that the number of cross folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(estimator = gbm, \n",
    "                           param_grid = gs_inputs, \n",
    "                           scoring = 'roc_auc', \n",
    "                           cv = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Model\n",
    "Fitting the model will be the longest run time you’ll experience if you’re running the code in this chapter yourself.  The actual function itself is so simple, but this is truly the “building the model” step all of this work has led up to.  While a bit anticlimactic, I will also prefer a simple process over a complex one!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='deprecated',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [4, 5, 6], 'min_samples_split': [25, 50],\n",
       "                         'n_estimators': [150, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC (Accuracy Metric)\n",
    "A critically important step in the modeling process is to pick the right metric to evaluate accuracy.  Which metrics you can use depend on which type of model you’re using (see additional modeling terminology section above for difference between classification and regression in ML).  Since the model we’re building is a classification model, we want to leverage metrics that are designed for it.  For the complete list of accuracy metrics in the sklearn library, please go [here]( https://scikit-learn.org/stable/modules/model_evaluation.html).  \n",
    "\n",
    "For this model we will utilize ROC AUC (receiver operating curve area under the curve).  The actual math behind it is beyond the scope of this chapter, so if you’re interested in getting more into the weeds of how the metric is calculated, Google has a nice article more specifics of the calculation.  For our purposes, know the metric takes into account 2 pieces: true positives (how often did our model predicts someone would terminate and they **did** terminate) and false positives (how often did our model predict someone would terminate but they **didn’t** terminate).  Using both of these, the metric is quite robust against the many pitfalls other classification metrics experience.\n",
    "\n",
    "The metric will come out as a number between 0.5 to 1.0, with 0.5 meaning the model is as good as random chance and 1.0 meaning the model is predicting perfectly.  With that, most of the time your number falls in-between 0.5 and 1.0, so how do we know what is good and what isn’t?  You can leverage the following ranges as a rule of thumb:\n",
    "*0.5 to 0.6*: Your model isn’t very good.  You should consider adding more data (more row or more columns) if you have it available.  If you have added the extent of your available data, using a model to predict this outcome may prove difficult.\n",
    "\n",
    "*0.6 to 0.7*: There is some hope here, but you can’t take your model and put it into production.  Consider going back and doing some additional feature engineering and adding more data if you have it.\n",
    "\n",
    "*0.7 to 0.8*: If you get into the higher 0.7’s, you’re getting to a model that can be put into use with the appropriate use case.  If you’re using the model in the HR space to gain awareness, I’d feel comfortable putting this model out.  If you’re tying this model to an intervention, specifically an intervention where higher risk employees get a financial benefit (gift card, swag, etc), I’d recommend going back and seeing if more data can be added or engineered.\n",
    "\n",
    "*0.8 to 0.9*: Give yourself a high five, in this range your model is looking good and should be usable for any use case (assuming you don’t have some partial leakage going on).  \n",
    "\n",
    "*0.9 to 1.0*: This should be better than the 0.8 to 0.9 range, right?  It depends.  Once you start getting into the 0.9 range, especially in the HR space where human behavior drives a lot of what we measure, it should give you pause.  While you could have a really good model, you could also have leakage going on.  I’ve built a few models that had AUC’s in the mid 0.9’s and its been about 50-50 on there being leakage vs. my model just being that awesome.\n",
    "\n",
    "Within the GridSearchCV function, we had specified roc_auc as our scoring metric for the grid search.  We can extract the best AUC from the grid search and display it which I have done below.  As we can see from our example dataset, the AUC isn’t great and will likely warrant some additional data.  However, this serves as a good example.  **Don’t stop here** if you see a less than desirable AUC score, especially if you have a smaller dataset.  With two cross folds, we’re further splitting our already smaller than desired dataset.  Additionally, our initial grid search was quite limited, so how can we check which hyperparameters grid search selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC AUC from Grid Search:  0.6198163025587877\n"
     ]
    }
   ],
   "source": [
    "print(\"Best ROC AUC from Grid Search: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Hyperparameters\n",
    "We can check which hyperparameters came back with the best AUC score using the below code.  We can see that it essentially took the “greediest” of the options.  It selected to have the most trees, the greatest depth, and the smallest sample split.  This likely means we’re leaving something on the table because our grid search was limited in the beginning to just make sure what we were running works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search:  {'max_depth': 6, 'min_samples_split': 25, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters from Grid Search: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting and Finding Final Model Score\n",
    "Even though we know there is likely some predictability being left on the table, let’s go through the full process of making your predictions and then getting your final score before revisiting our grid search parameters.\n",
    "The roc_auc function requires you to predict the probability of the outcome rather than an absolute 1 or 0.  I personally find predicting the probability more useful in general, especially in the context of HR.  If you speak in absolutes, you’re making it more difficult to get buy in from stakeholders who are already likely skeptics of what your model will be saying regardless (especially if it defies their years of experience in HR).\n",
    "\n",
    "A sample of the predictions are printed out.  You’ll see they come through as a percentage.  I personally had some confusion when trying to understand how a classification model (binary outcome, not numbers) can produce a numeric output.  To generate the probabilities, it is taking the number of observations at the end of the decision tree and identifying how many fit into each category.  For example, say there are 10 employees who are Executives, in Technology, under the age of 60, with a performance rating of 2.  Of those 10 employees, 7 terminated and 3 did not.  The probability for terminating is then 70%.  The actual math behind this is a bit more complex, however the same general principle applies even with the additional complexities of the GBM!\n",
    "\n",
    "Once you have predicted on the test set using the model you’ve built, the final step is to put it through the final roc_auc calculation.  Interestingly, we find that the overall model score is better than the best score from the grid search.  Why could that be?  It is most likely due to the cross validation being done on our smaller dataset.  Remember, the final score we just created is on a randomized 30% of our data that the model hasn’t seen yet.  This means the model can’t be overfitting on data it hasn’t seen before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04191404 0.01325427 0.04147995 ... 0.03581116 0.01673108 0.02464097]\n",
      "Final Model AUC Score:  0.690777968309237\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict_proba(X_test)[:,1]\n",
    "print(y_pred)\n",
    "print(\"Final Model AUC Score: \",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For fun, doing some additional grid search\n",
    "Let's do some additional grid search and expand our hyperparameter ranges based on what we observed with the hyperparameters being selected in our first grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC AUC from Grid Search:  0.6339904461592456\n",
      "Best Parameters from Grid Search:  {'max_depth': 8, 'min_samples_split': 10, 'n_estimators': 400}\n",
      "Final Model AUC Score:  0.7235168543983315\n"
     ]
    }
   ],
   "source": [
    "gs_inputs = {'n_estimators': [200, 300, 400], \n",
    "             'min_samples_split': [10, 25], \n",
    "             'max_depth': [6, 8]}\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(estimator = gbm, \n",
    "                           param_grid = gs_inputs, \n",
    "                           scoring = 'roc_auc', \n",
    "                           cv = 2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best ROC AUC from Grid Search: \", grid_search.best_score_)\n",
    "print(\"Best Parameters from Grid Search: \", grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict_proba(X_test)[:,1]\n",
    "print(\"Final Model AUC Score: \",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've gotten a better model, however not one that we would still want to put into use.  That is okay and quite realistic in most cases!  Think about the number of variables we have included in this example dataset (10 inputs variables).  It is quite limited and finding a highly accurate model would be unlikely in the real world given the complexity of turnover and the noise introduced by human decision making.  A goal of this chapter is to provide you a realistic example and I think the results from this model provide that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding our Model\n",
    "The most common objection to using a tree based model is the lack of interpretability of the results.  This is completely valid and justified criticism.  There are some tools we can leverage to help with understanding what the model cares about the most.  The one I will highlight here is the feature importance graph.  Importance is defined by the number of times the feature is used to split on in our model.  Since in a tree based model, features with the most predictive power are split on earlier in the model, the features that are consistently being used across our various trees will bubble to the top here.  Using some code, we can extract the feature importance and then visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12f80577888>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "winning_model = GradientBoostingClassifier(n_estimators = 400, min_samples_split = 10, max_depth = 8)\n",
    "winning_model.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.DataFrame(winning_model.feature_importances_,\n",
    "                                       index = df_dummied.iloc[:,:-1].columns,\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importances[feature_importances['importance'] >= .01].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things I want to point out here when interpreting this graph.  First, this is what is “important”, meaning it doesn’t indicate a direction relationship.  For example, saying “more salary means more risk of turnover” is not a correct interpretation.  Rather “salary is the most important variable to this model” is the correct interpretation.  The second point is that you can’t over index too heavily on all items that show up on this graph.  For example, the turnover logic to create this dataset does not mention gender or department variables at all, however it shows them as variables that carry at least some importance.  Why is that?  Think in terms of random chance.  The dataset was created using random number generation, so there is a chance that department or gender plays an impact on turnover behavior.  There is also a chance that it is just noise and not something to read into.\n",
    "\n",
    "When reading this graph, look for the variables that are significantly higher than the others.  In this, anything below performance rating probably isn’t worth thinking about as an important variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our Model to Predict\n",
    "The entire purpose of building a model is to use it to predict!  To do this, is the same as how we are treating the test dataset (minus the score calculation).  With a turnover model, you’d use all of your employee’s most recent record to then predict out the next X months you have set your target variable for.  Here is some pseudo code to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata_predictions = your_model.predict_proba(X_newdata)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Summary\n",
    "Throughout this chapter we went from the beginning of the modeling process where we ingest our raw data and clean it up to the end of the modeling process where we are able to utilize it for future predictions.  Based purely on the amount of code in each section, I hope it has become clear that the majority of the modeling process becomes before you actually build the model.  When you consider the context of HR data, this is going to be even more true.  Most companies do not have their HR data in a single database, cleaned, and ready to be pulled for modeling projects.  It is more likely you’re having to pull your information from multiple sources and still do a significant amount of cleaning.  The general rule of thumb is 80% data clean up and 20% actual modeling.  With HR data, expect that to be closer to 90% data clean up to 10% modeling.\n",
    "\n",
    "While this may be frustrating, business leaders look to invest in projects and people who prove value.  If you’re able to take your employee data, build a turnover model on it, and create an intervention that reduces turnover by even 0.5%, you’re saving your company an incredible amount of money (regardless of the size of your company).  Showing this type of value is how you can then get additional leverage to push your HR leaders to invest in a data infrastructure that potentially turns your data cleaning to modeling ratio to 70-30 or even 60-40!\n",
    "\n",
    "This example showed you how to build a turnover model which seems to be the hottest topic.  You can take this code and adjust it for your own company’s data.  Beyond this, the same type of modeling framework can be leveraged for other types of predictions as well!  This is nice because once you get a hang of this type of framework, it helps get you closer to the scalable analytics.  Rather than starting from scratch every time, you’re able to leverage a significant amount of your code from other projects to expedite the development time of the next project!\n",
    "\n",
    "Throughout my time in the HR analytics space and various interviews, the question about a model that predicts turnover has been the most common.  I hope this chapter gives you a framework and some additional knowledge to feel comfortable building and speaking to a model that predicts turnover!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
